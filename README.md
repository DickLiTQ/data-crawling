# data-crawling
Containing my trial for data crawling in several websites.

------------------
## Overture
I use **requests** and **webdriver** for data crawling. If you don't have these tools, you are supposed to obtain them at first.

Use **pip** to install **requests** and **selenium**.
```{console}
pip install requests
pip install selenium
```
To mine a dynamic website, we need **PhantomJS** or **Chromedriver**. Here are some notes for download them.
- http://phantomjs.org
- http://phantomjs.org/download.html
- http://chromedriver.chromium.org
- http://chromedriver.storage.googleapis.com/index.html

It is easy for you to install them by google or baidu it.

## Crawling on different websites



